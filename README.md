# spelling-corrector

Built from scratch a spelling corrector in Python. It includes:
1. tokenization
2. Levenshtein distance-based non-word spelling correction
3. de-tokenization
As an example use case, I considered a version of Jane Austen’s Sense and Sensibility (available via nltk’s gutenberg corpus) corrupted by random insertions,
deletions, and substitutions. See for reference gen_corrupted.py.
